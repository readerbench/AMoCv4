{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated Model of Comprehension version 4.0 Notebook"
      ],
      "metadata": {
        "id": "tJSaW6zoEtxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a notebook where you can play or develop based on AMoC v4.0. You will be required to provide an OpenAI API key in order to make calls to ChatGPT API."
      ],
      "metadata": {
        "id": "9y3Q_u1CFWxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook should be in viewer mode only, except if you are an editor. This is required since we don't want people to put API keys into the notebook so that others will be able to use it.\n",
        "\n",
        "To use this notebook you can:\n",
        "a. go to File -> Save a copy in Drive, and use it as your own Notebook\n",
        "b. go to File -> Open in playground mode, this will allow you to make changes to the notebook and they will not be saved."
      ],
      "metadata": {
        "id": "ZqiS201qF8Yx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before going on please set up some constants. You can go ahead and read the notebook and then come back here as well."
      ],
      "metadata": {
        "id": "046Fm89oIYwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPEN_AI_API_KEY = \"\"\n",
        "OPEN_AI_ORGANIZATION = \"\"\n",
        "MAX_DISTANCE_FROM_ACTIVE_NODES = 2\n",
        "MAX_NEW_CONCEPTS = 3\n",
        "MAX_NEW_PROPERTIES = 3\n",
        "CONTEXT_LENGTH = 1 # Experimental parameter to include more sentences as a \"known\" text. Should be equal to 1 to replicate the behaviour specified in the paper.\n",
        "EDGE_FORGET = 2\n",
        "NR_RELEVANT_EDGES = 15\n",
        "DEBUG = False"
      ],
      "metadata": {
        "id": "W_b3BkwqWeD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code part"
      ],
      "metadata": {
        "id": "kUPpSkgXXnXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install openai library\n",
        "!pip install openai\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "f8XQrmrqFDIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaKyo6Mp3KAr"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "from typing import List, Tuple, Dict, Set, Union, Optional\n",
        "from enum import Enum\n",
        "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
        "from collections import deque\n",
        "import spacy\n",
        "from spacy.tokens import Token, Doc, Span\n",
        "import logging\n",
        "import time\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Node type enum, they can be either a concept or a property."
      ],
      "metadata": {
        "id": "FbB-9cUuIXfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NodeType(Enum):\n",
        "    CONCEPT = 1\n",
        "    PROPERTY = 2"
      ],
      "metadata": {
        "id": "hLGi-XZ63sep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Node source enum, they can be either text based or inference based."
      ],
      "metadata": {
        "id": "_Gpz7A0EIppo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NodeSource(Enum):\n",
        "    TEXT_BASED = 1\n",
        "    INFERENCE_BASED = 2"
      ],
      "metadata": {
        "id": "54AXOTsK30ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The class for a Node in the AMoC graph."
      ],
      "metadata": {
        "id": "46Ho-VXEIvoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "\n",
        "    def __init__(self, lemmas: List[str], actual_text: str, node_type: NodeType,\n",
        "                 node_source: NodeSource, score: int) -> None:\n",
        "        self.lemmas: List[str] = lemmas\n",
        "        self.actual_texts: Dict[str, int] = {actual_text: 1}\n",
        "        self.node_type: NodeType = node_type\n",
        "        self.node_source: NodeSource = node_source\n",
        "        self.score = score\n",
        "        self.edges: List[Edge] = []\n",
        "\n",
        "    def __eq__(self, other: 'Node') -> bool:\n",
        "        return self.lemmas == other.lemmas\n",
        "\n",
        "    def __hash__(self) -> int:\n",
        "        return hash(tuple(self.lemmas))\n",
        "\n",
        "    def add_actual_text(self, actual_text: str) -> None:\n",
        "        if actual_text in self.actual_texts:\n",
        "            self.actual_texts[actual_text] += 1\n",
        "        else:\n",
        "            self.actual_texts[actual_text] = 1\n",
        "\n",
        "    def get_text_representer(self) -> str:\n",
        "        # return max count from actual_texts\n",
        "        return max(self.actual_texts, key=self.actual_texts.get) # type: ignore\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return f\"{self.get_text_representer()} ({self.node_type.name}, \\\n",
        "                    {self.node_source.name}, {self.score})\"\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return str(self)"
      ],
      "metadata": {
        "id": "VS4Fcn68Bfi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The class for an Edge in the AMoC graph."
      ],
      "metadata": {
        "id": "0r7WqPJrI0mA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Edge:\n",
        "\n",
        "    def __init__(self, source_node: Node, dest_node: Node, label: str,\n",
        "                 forget_score: int, active: bool = True) -> None:\n",
        "        self.source_node: Node = source_node\n",
        "        self.dest_node: Node = dest_node\n",
        "        self.active: bool = active\n",
        "        self.label: str = label\n",
        "        self.forget_score: int = forget_score\n",
        "        self.embedding = get_embedding(label, engine='text-embedding-ada-002')\n",
        "        self.similarity_threshold = 0.8\n",
        "\n",
        "    def fade_away(self) -> None:\n",
        "        self.forget_score -= 1\n",
        "        if self.forget_score <= 0:\n",
        "            self.active = False\n",
        "\n",
        "    def is_similar(self, other_edge: 'Edge') -> bool:\n",
        "        return cosine_similarity(self.embedding, other_edge.embedding) > self.similarity_threshold\n",
        "\n",
        "    def __eq__(self, other: 'Edge') -> bool:\n",
        "        return self.source_node == other.source_node and self.dest_node == other.dest_node and self.label == other.label\n",
        "\n",
        "    def __hash__(self) -> int:\n",
        "        return hash((self.source_node, self.dest_node, self.label))\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return f\"{self.source_node.get_text_representer()} --{self.label} ({'active' if self.active else 'inactive'})--> {self.dest_node.get_text_representer()} ({self.forget_score})\"\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return self.__str__()"
      ],
      "metadata": {
        "id": "lCDRLGuoB5hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The class for the Graph in AMoC v4.0."
      ],
      "metadata": {
        "id": "DWLKLfMLI4sW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Graph:\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.nodes: Set[Node] = set()\n",
        "        self.edges: Set[Edge] = set()\n",
        "\n",
        "    def add_or_get_node(self, lemmas: List[str], actual_text: str,\n",
        "                        node_type: NodeType, node_source: NodeSource) -> Node:\n",
        "        node = self.get_node(lemmas)\n",
        "        if node is None:\n",
        "            node = Node(lemmas, actual_text, node_type, node_source, 0)\n",
        "            self.nodes.add(node)\n",
        "        else:\n",
        "            node.add_actual_text(actual_text)\n",
        "        return node\n",
        "\n",
        "    def get_node(self, lemmas: List[str]) -> Optional[Node]:\n",
        "        for node in self.nodes:\n",
        "            if node.lemmas == lemmas:\n",
        "                return node\n",
        "        return None\n",
        "\n",
        "    def get_edge_by_nodes_and_label(self, source_node: Node, dest_node: Node, label: str) -> Optional[Edge]:\n",
        "        for edge in self.edges:\n",
        "            if edge.source_node == source_node and edge.dest_node == dest_node and edge.label == label:\n",
        "                return edge\n",
        "        return None\n",
        "\n",
        "    def get_edge(self, edge: Edge) -> Optional[Edge]:\n",
        "        for other_edge in self.edges:\n",
        "            if edge == other_edge:\n",
        "                return other_edge\n",
        "        return None\n",
        "\n",
        "    def add_edge(self, source_node: Node, dest_node: Node, label: str, edge_forget: int) -> Optional[Edge]:\n",
        "        edge = Edge(source_node, dest_node, label, edge_forget)\n",
        "        if self.check_if_similar_edge_exists(edge, edge_forget):\n",
        "            return None\n",
        "        self.edges.add(edge)\n",
        "        source_node.edges.append(edge)\n",
        "        dest_node.edges.append(edge)\n",
        "        return edge\n",
        "\n",
        "    def check_if_similar_edge_exists(self, edge: Edge, edge_forget: int) -> bool:\n",
        "        if edge in self.edges:\n",
        "            self.get_edge(edge).forget_score = edge_forget\n",
        "            self.get_edge(edge).active = True\n",
        "            return True\n",
        "        for other_edge in self.edges:\n",
        "            if edge.source_node == other_edge.source_node and edge.dest_node == other_edge.dest_node:\n",
        "                if edge.source_node.node_type == NodeType.CONCEPT and edge.dest_node.node_type == NodeType.PROPERTY:\n",
        "                    other_edge.forget_score = edge_forget\n",
        "                    other_edge.active = True\n",
        "                    return True # this edge represents an edge that connects a concept node with a property node\n",
        "                if edge.dest_node.node_type == NodeType.CONCEPT and edge.source_node.node_type == NodeType.PROPERTY:\n",
        "                    other_edge.forget_score = edge_forget\n",
        "                    other_edge.active = True\n",
        "                    return True # same as above\n",
        "                if edge.is_similar(other_edge):\n",
        "                    # update edge type if necessary\n",
        "                    other_edge.forget_score = edge_forget\n",
        "                    other_edge.active = True\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    def bfs_from_activated_nodes(self, activated_nodes: List[Node]) -> Dict[Node, int]:\n",
        "        distances = {}\n",
        "        queue = deque([(node, 0) for node in activated_nodes])\n",
        "        while queue:\n",
        "            curr_node, curr_distance = queue.popleft()\n",
        "            if curr_node not in distances:\n",
        "                distances[curr_node] = curr_distance\n",
        "                for edge in curr_node.edges:\n",
        "                    if edge.active:\n",
        "                        next_node = edge.dest_node if edge.source_node == curr_node else edge.source_node\n",
        "                        queue.append((next_node, curr_distance + 1)) # type: ignore\n",
        "        return distances\n",
        "\n",
        "    def set_nodes_score_based_on_distance_from_active_nodes(self, activated_nodes: List[Node]) -> None:\n",
        "        distances_to_activated_nodes = self.bfs_from_activated_nodes(activated_nodes)\n",
        "        for node in self.nodes:\n",
        "            node.score = distances_to_activated_nodes.get(node, 100)\n",
        "\n",
        "    def get_word_lemma_score(self, word_lemmas: List[str]) -> Optional[float]:\n",
        "        for node in self.nodes:\n",
        "            if node.lemmas == word_lemmas:\n",
        "                return node.score\n",
        "        return None\n",
        "\n",
        "    def get_top_k_nodes(self, nodes: List[Node], k: int) -> List[Node]:\n",
        "        return sorted(nodes, key=lambda node: node.score)[:k]\n",
        "\n",
        "    def get_top_concepts_nodes(self, k: int) -> List[Node]:\n",
        "        nodes = [node for node in self.nodes if node.node_type == NodeType.CONCEPT]\n",
        "        return self.get_top_k_nodes(nodes, k)\n",
        "\n",
        "    def get_top_text_based_concepts(self, k: int) -> List[Node]:\n",
        "        nodes = [node for node in self.nodes if node.node_type == NodeType.CONCEPT and node.node_source == NodeSource.TEXT_BASED]\n",
        "        return self.get_top_k_nodes(nodes, k)\n",
        "\n",
        "    def get_active_nodes(self, score_threshold: int, only_text_based: bool = False) -> List[Node]:\n",
        "        return [node for node in self.nodes if node.score <= score_threshold and (not only_text_based or node.node_source == NodeSource.TEXT_BASED)]\n",
        "\n",
        "    def get_nodes_str(self, nodes: List[Node]) -> str:\n",
        "        nodes_str = \"\"\n",
        "        for node in sorted(nodes, key=lambda node: node.score):\n",
        "            nodes_str += \"- \" + f\"{node.get_text_representer()} (type: {node.node_type}) (score: {node.score})\" + \"\\n\"\n",
        "        return nodes_str\n",
        "\n",
        "    def get_edges_str(self, nodes: List[Node], only_text_based: bool = False, only_active: bool = True) -> Tuple[str, List[Edge]]:\n",
        "        used_edges = set()\n",
        "        edges_str = \"\"\n",
        "        count = 1\n",
        "        for node in sorted(nodes, key=lambda node: node.score):\n",
        "            for edge in node.edges:\n",
        "                if only_active and edge.active == False:\n",
        "                    continue\n",
        "                if edge not in used_edges:\n",
        "                    if not only_text_based:\n",
        "                        edges_str += f\"{count}. {edge.source_node.get_text_representer()} - {edge.label} (edge) - {edge.dest_node.get_text_representer()}\" + \"\\n\"\n",
        "                        used_edges.add(edge)\n",
        "                        count += 1\n",
        "                    else:\n",
        "                        if edge.source_node.node_source == NodeSource.TEXT_BASED and edge.dest_node.node_source == NodeSource.TEXT_BASED:\n",
        "                            edges_str += f\"{count}. {edge.source_node.get_text_representer()} - {edge.label} (edge) - {edge.dest_node.get_text_representer()}\" + \"\\n\"\n",
        "                            used_edges.add(edge)\n",
        "                            count += 1\n",
        "        return edges_str, list(used_edges)\n",
        "\n",
        "    def get_active_graph_repr(self) -> str:\n",
        "        edges = [edge for edge in self.edges if edge.active]\n",
        "        nodes = set()\n",
        "        for edge in edges:\n",
        "            nodes.add(edge.source_node)\n",
        "            nodes.add(edge.dest_node)\n",
        "        s = \"nodes:\\n\"\n",
        "        for node in nodes:\n",
        "            s += str(node) + \"\\n\"\n",
        "        s += \"\\nedges:\\n\"\n",
        "        for edge in edges:\n",
        "            s += str(edge) + \"\\n\"\n",
        "        return s\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return \"nodes: {}\\n\\nedges: {}\".format(\"\\n\".join([str(x) for x in self.nodes]), \"\\n\".join([str(x) for x in self.edges]))\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return self.__str__()"
      ],
      "metadata": {
        "id": "Q0nOsCYvCODN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompts"
      ],
      "metadata": {
        "id": "A2S0To8kJAR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_RELATIONSHIPS_PROMPT = \"\"\"I want to build a knowledge graph using the provided text. The graph should consist of two types of nodes: concept nodes and property nodes. Concepts nodes represent objects or persons from the story and are generally represented by nouns in the text. Property nodes describe the concepts nodes and are generally represented by adjectives in the text. An edge connects a concept to another concept or a concept to a property, and it is described by a relationship between the connected nodes.\n",
        "\n",
        "The format for representing the graph is as follows: ('concept1', 'relation (edge)', 'concept2') or ('concept1', 'relation (edge)', 'property1').\n",
        "\n",
        "I already extracted the nodes from the text and these ones you should use:\n",
        "{nodes_from_text}\n",
        "\n",
        "I also have the knowledge graph:\n",
        "Nodes (with their types, and a score of how central they are in the story (0 is most central, 1 less central, etc.)):\n",
        "{nodes_from_graph}\n",
        "\n",
        "Edges (relationships between the nodes):\n",
        "{edges_from_graph}\n",
        "\n",
        "I want you to tell me the relationships (edges) between the nodes from the text themselves. And also between the nodes from the text and the other nodes from the graph (here prioritize the relationships based on the score). The text is:\n",
        "{text}\n",
        "\n",
        "List them as a Python list and do not provide additional explanation.\"\"\"\n",
        "\n",
        "NEW_RELATIONSHIPS_FOR_FIRST_SENTENCE_PROMPT = \"\"\"I want to build a knowledge graph using the provided text. The graph should consist of two types of nodes: concept nodes and property nodes. Concepts nodes represent objects or persons from the story and are generally represented by nouns in the text. Property nodes describe the concepts nodes and are generally represented by adjectives in the text. An edge connects a concept to another concept or a concept to a property, and it is described by a relationship between the connected nodes.\n",
        "\n",
        "The format for representing the graph is as follows: ('concept1', 'relation (edge)', 'concept2') or ('concept1', 'relation (edge)', 'property1').\n",
        "\n",
        "I already extracted the nodes from the text and these ones you should use:\n",
        "{nodes_from_text}\n",
        "\n",
        "I want you to tell me the relationships (edges) between the nodes given the text. The text is:\n",
        "{text}\n",
        "\n",
        "List them as a Pyhon list and do not provide additional explanation.\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "INFER_OBJECTS_AND_PROPERTIES_PROMPT = \"\"\"I want to build a knowledge graph using the provided text. The graph should consist of two types of nodes: concept nodes and property nodes. Concepts nodes represent objects or persons from the story and are generally represented by nouns in the text. Property nodes describe the concepts nodes and are generally represented by adjectives in the text. An edge connects a concept to another concept or a concept to a property, and it is described by a relationship between the connected nodes.\n",
        "\n",
        "The format for representing the graph is as follows: ('concept1', 'relation (edge)', 'concept2') or ('concept1', 'relation (edge)', 'property1').\n",
        "\n",
        "I already extracted the nodes from the text:\n",
        "{nodes_from_text}\n",
        "\n",
        "I also have the current knowledge graph:\n",
        "Nodes (with their types, and a score of how central they are in the story (0 is most central, 1 less central, etc.)):\n",
        "{nodes_from_graph}\n",
        "\n",
        "Edges (relationships between the nodes):\n",
        "{edges_from_graph}\n",
        "\n",
        "Generate a list of concepts and properties that are in line with the overall coherence and sense within the given text and the knowledge graph, but they are not in the text. The text is:\n",
        "{text}\n",
        "\n",
        "List them in the following format and explain the role of the text and the knowledge graph in the decesion making process:\n",
        "{{\n",
        "    \"concepts\": [concept1, concept2, ...],\n",
        "    \"properties\": [property1, property2, ...]\n",
        "}}\"\"\"\n",
        "\n",
        "GENERATE_NEW_INFERRED_RELATIONSHIPS_PROMPT = \"\"\"I want to build a knowledge graph using the provided text. The graph should consist of two types of nodes: concept nodes and property nodes. Concepts nodes represent objects or persons from the story and are generally represented by nouns in the text. Property nodes describe the concepts nodes and are generally represented by adjectives in the text. An edge connects a concept to another concept or a concept to a property, and it is described by a relationship between the connected nodes.\n",
        "\n",
        "The format for representing the graph is as follows: ('concept1', 'relation (edge)', 'concept2') or ('concept1', 'relation (edge)', 'property1').\n",
        "\n",
        "I already extracted the nodes from the text:\n",
        "{nodes_from_text}\n",
        "\n",
        "I also have the current knowledge graph:\n",
        "Nodes (with their types, and a score of how central they are in the story (0 is most central, 1 less central, etc.)):\n",
        "{nodes_from_graph}\n",
        "\n",
        "Edges (relationships between the nodes):\n",
        "{edges_from_graph}\n",
        "\n",
        "And I already have additional concepts and properties that are in line with the overall coherence and sense within the given text:\n",
        "concepts: {concepts}\n",
        "properties: {properties}\n",
        "\n",
        "Create relationships between the nodes from the text and the new concepts and the new properties (as you see fit). The text is:\n",
        "{text}\n",
        "\n",
        "Provide them in the following format:\n",
        "{{\n",
        "    \"concept_relationships\": [concept_relation1, concept_relation2, ...],\n",
        "    \"property_relationships\": [property_relation1, property_relation2, ...]\n",
        "}}\"\"\"\n",
        "\n",
        "\n",
        "INFER_OBJECTS_AND_PROPERTIES_FIRST_SENTENCE_PROMPT = \"\"\"I want to build a knowledge graph using the provided text. The graph should consist of two types of nodes: concept nodes and property nodes. Concepts nodes represent objects or persons from the story and are generally represented by nouns in the text. Property nodes describe the concepts nodes and are generally represented by adjectives in the text. An edge connects a concept to another concept or a concept to a property, and it is described by a relationship between the connected nodes.\n",
        "\n",
        "The format for representing the graph is as follows: ('concept1', 'relation (edge)', 'concept2') or ('concept1', 'relation (edge)', 'property1').\n",
        "\n",
        "I already extracted the nodes from the text:\n",
        "{nodes_from_text}\n",
        "\n",
        "Generate a list of concepts and properties that are in line with the overall coherence and sense within the given text, but they are not in the text. The text is:\n",
        "{text}\n",
        "\n",
        "List them in the following format:\n",
        "{{\n",
        "    \"concepts\": [concept1, concept2, ...],\n",
        "    \"properties\": [property1, property2, ...]\n",
        "}}\"\"\"\n",
        "\n",
        "GENERATE_NEW_INFERRED_RELATIONSHIPS_FIRST_SENTENCE_PROMPT = \"\"\"I want to build a knowledge graph using the provided text. The graph should consist of two types of nodes: concept nodes and property nodes. Concepts nodes represent objects or persons from the story and are generally represented by nouns in the text. Property nodes describe the concepts nodes and are generally represented by adjectives in the text. An edge connects a concept to another concept or a concept to a property, and it is described by a relationship between the connected nodes.\n",
        "\n",
        "The format for representing the graph is as follows: ('concept1', 'relation (edge)', 'concept2') or ('concept1', 'relation (edge)', 'property1').\n",
        "\n",
        "I already extracted the nodes from the text:\n",
        "{nodes_from_text}\n",
        "\n",
        "And I already have additional concepts and properties that are in line with the overall coherence and sense within the given text:\n",
        "concepts: {concepts}\n",
        "properties: {properties}\n",
        "\n",
        "Create relationships between the nodes from the text and the new concepts and the new properties (as you see fit). The text is:\n",
        "{text}\n",
        "\n",
        "Provide them in the following format:\n",
        "{{\n",
        "    \"concept_relationships\": [concept_relation1, concept_relation2, ...],\n",
        "    \"property_relationships\": [property_relation1, property_relation2, ...]\n",
        "}}\"\"\"\n",
        "\n",
        "SELECT_RELEVANT_EDGES_PROMPT = \"\"\"You have the following edges from a knowledge graph in the format: node - edge - node\n",
        "{edges}\n",
        "\n",
        "As you can see, they are numbered. Tell me what edges are related to / support / contradict the following text.\n",
        "{text}\n",
        "\n",
        "Provide them in the following format (a list of numbers):\n",
        "[1, 2, 3, ...]\n",
        "\"\"\"\n",
        "\n",
        "REPLACE_PRONOUNS_PROMPT = 'Replace the pronouns \"he, she, they\" with the persons / nouns from the text that they are referring to. Sometimes there is no such reference and you should leave them as they are. Do not come up with imaginary names for the pronouns, they must be in the text. The text is:\\n'"
      ],
      "metadata": {
        "id": "Oe0LnaaPEQyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class for interacting with ChatGPT"
      ],
      "metadata": {
        "id": "IiFaiN58JEfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OpenAIChatGPT:\n",
        "\n",
        "    def __init__(self, debug=False):\n",
        "        openai.organization = OPEN_AI_ORGANIZATION\n",
        "        openai.api_key = OPEN_AI_API_KEY\n",
        "        self.debug = debug\n",
        "        if debug:\n",
        "            logging.basicConfig(level=logging.DEBUG)\n",
        "        else:\n",
        "            logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    def read_open_sk_key(self):\n",
        "        with open('openai.sk') as f:\n",
        "            return f.read().strip()\n",
        "\n",
        "    def call_chatgpt(self, prompt):\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo-0301\",\n",
        "                messages=[\n",
        "                        {\"role\": \"user\", \"content\": prompt},\n",
        "                    ],\n",
        "                temperature=0.8\n",
        "                )\n",
        "            if self.debug:\n",
        "                logging.debug(\"\\n\\n\" + str(response) + \"\\n\\n\")\n",
        "            return response['choices'][0]['message']['content']\n",
        "        except:\n",
        "            time.sleep(10)\n",
        "            return self.call_chatgpt(prompt)\n",
        "\n",
        "    def parse_for_dict(self, sentence_word_connections_response):\n",
        "        try:\n",
        "            start_index = sentence_word_connections_response.index(\"{\")\n",
        "            num_braces = 1\n",
        "            end_index = None\n",
        "            for i in range(start_index + 1, len(sentence_word_connections_response)):\n",
        "                if sentence_word_connections_response[i] == \"{\":\n",
        "                    num_braces += 1\n",
        "                elif sentence_word_connections_response[i] == \"}\":\n",
        "                    num_braces -= 1\n",
        "                    if num_braces == 0:\n",
        "                        end_index = i\n",
        "                        break\n",
        "            if end_index is not None:\n",
        "                json_str = sentence_word_connections_response[start_index:end_index + 1]\n",
        "                json_obj = eval(json_str)\n",
        "                return json_obj\n",
        "            else:\n",
        "                raise ValueError(\"No json object found in response\")\n",
        "        except:\n",
        "            print(\"No json object found in response\")\n",
        "            return None\n",
        "\n",
        "    def extract_list_from_string(self, string):\n",
        "        # Find the start and end indices of the list in the string\n",
        "        start_index = string.find('[')\n",
        "        end_index = string.rfind(']')\n",
        "\n",
        "        # Extract the substring containing the list\n",
        "        list_string = string[start_index:end_index+1]\n",
        "\n",
        "        # Use eval to convert the list string to a Python list\n",
        "        try:\n",
        "            result = eval(list_string)\n",
        "            if isinstance(result, list):\n",
        "                return result\n",
        "            else:\n",
        "                logging.error(\"No list found in the string.\")\n",
        "                return []\n",
        "        except SyntaxError:\n",
        "            logging.error(\"No list found in the string.\")\n",
        "            return []\n",
        "\n",
        "    def get_new_relationships(self, nodes_from_text, nodes_from_graph, edges_from_graph, text):\n",
        "        prompt = NEW_RELATIONSHIPS_PROMPT.format(nodes_from_text=nodes_from_text, nodes_from_graph=nodes_from_graph, edges_from_graph=edges_from_graph, text=text)\n",
        "        response = self.call_chatgpt(prompt)\n",
        "        return self.extract_list_from_string(response)\n",
        "\n",
        "    def get_new_relationships_first_sentence(self, nodes_from_text, text):\n",
        "        prompt = NEW_RELATIONSHIPS_FOR_FIRST_SENTENCE_PROMPT.format(nodes_from_text=nodes_from_text, text=text)\n",
        "        response = self.call_chatgpt(prompt)\n",
        "        return self.extract_list_from_string(response)\n",
        "\n",
        "    def infer_objects_and_properties(self, nodes_from_text, nodes_from_graph, edges_from_graph, text):\n",
        "        prompt = INFER_OBJECTS_AND_PROPERTIES_PROMPT.format(nodes_from_text=nodes_from_text, nodes_from_graph=nodes_from_graph, edges_from_graph=edges_from_graph, text=text)\n",
        "        response = self.call_chatgpt(prompt)\n",
        "        return self.parse_for_dict(response)\n",
        "\n",
        "    def generate_new_inferred_relationships(self, nodes_from_text, nodes_from_graph, edges_from_graph, concepts, properties, text):\n",
        "        prompt = GENERATE_NEW_INFERRED_RELATIONSHIPS_PROMPT.format(nodes_from_text=nodes_from_text, nodes_from_graph=nodes_from_graph, edges_from_graph=edges_from_graph, concepts=concepts, properties=properties, text=text)\n",
        "        response = self.call_chatgpt(prompt)\n",
        "        return self.parse_for_dict(response)\n",
        "\n",
        "    def infer_objects_and_properties_first_sentence(self, nodes_from_text, text):\n",
        "        prompt = INFER_OBJECTS_AND_PROPERTIES_FIRST_SENTENCE_PROMPT.format(nodes_from_text=nodes_from_text, text=text)\n",
        "        response = self.call_chatgpt(prompt)\n",
        "        return self.parse_for_dict(response)\n",
        "\n",
        "    def generate_new_inferred_relationships_first_sentence(self, nodes_from_text, concepts, properties, text):\n",
        "        prompt = GENERATE_NEW_INFERRED_RELATIONSHIPS_FIRST_SENTENCE_PROMPT.format(nodes_from_text=nodes_from_text, concepts=concepts, properties=properties, text=text)\n",
        "        response = self.call_chatgpt(prompt)\n",
        "        return self.parse_for_dict(response)\n",
        "\n",
        "    def get_relevant_edges(self, edges_from_graph, text):\n",
        "        prompt = SELECT_RELEVANT_EDGES_PROMPT.format(edges=edges_from_graph, text=text)\n",
        "        response = self.call_chatgpt(prompt)\n",
        "        return self.extract_list_from_string(response)"
      ],
      "metadata": {
        "id": "wToR1Yq-EEHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The actual AMoC implementation"
      ],
      "metadata": {
        "id": "0JWZI857JKib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AMoCv4:\n",
        "    def __init__(self, max_distance_from_active_nodes: int, max_new_concepts: int, max_new_properties: int,\n",
        "                 context_length: int, edge_forget: int, nr_relevant_edges: int,\n",
        "                 debug: bool = False) -> None:\n",
        "        \"\"\"\n",
        "        max_distance_from_active_nodes: maximum distance in terms of hops from activated nodes to consider\n",
        "        max_new_concepts: maximum number of new concepts that can be inferred\n",
        "        max_new_properties: maximum number of new properties that can be inferred\n",
        "        debug: enable debug mode\n",
        "        \"\"\"\n",
        "        self.max_distance_from_active_nodes = max_distance_from_active_nodes\n",
        "        self.max_new_concepts = max_new_concepts\n",
        "        self.max_new_properties = max_new_properties\n",
        "        self.context_length = context_length\n",
        "        self.edge_forget = edge_forget\n",
        "        self.nr_relevant_edges = nr_relevant_edges\n",
        "        self.graph = Graph()\n",
        "        self.spacy_nlp = spacy.load('en_core_web_lg')\n",
        "        self.chatgpt = OpenAIChatGPT(debug=debug)\n",
        "        if debug:\n",
        "            logging.basicConfig(level=logging.DEBUG)\n",
        "        else:\n",
        "            logging.basicConfig(level=logging.INFO)\n",
        "        logging.info(\"Hi! I am AMOC Star Plus.\")\n",
        "\n",
        "    def reset_graph(self) -> None:\n",
        "        self.graph = Graph()\n",
        "\n",
        "    def resolve_pronouns(self, text: str) -> str:\n",
        "        prompt = REPLACE_PRONOUNS_PROMPT + text\n",
        "        return self.chatgpt.call_chatgpt(prompt)\n",
        "\n",
        "    def analyze(self, text: str, replace_prononuns: bool):\n",
        "        if replace_prononuns:\n",
        "          text = self.resolve_pronouns(text)\n",
        "        doc = self.spacy_nlp(text)\n",
        "        prev_sentences = []\n",
        "        current_sentence = \"\"\n",
        "        for i, sent in enumerate(doc.sents):\n",
        "            logging.info(\"Processing sentence %d: %s\" % (i, sent))\n",
        "            if i == 0:\n",
        "                current_sentence = sent\n",
        "                prev_sentences.append(sent)\n",
        "                self.init_graph(sent)\n",
        "\n",
        "                inferred_concept_relationships, inferred_property_relationships = \\\n",
        "                        self.infer_new_relationships_step_0(sent)\n",
        "                print(\"Inferred concept relationships:\\n{inferred_concept_relationships}\")\n",
        "                print(\"Inferred property relationships:\\n{inferred_property_relationships}\")\n",
        "                self.add_inferred_relationships_to_graph_step_0(inferred_concept_relationships, NodeType.CONCEPT, sent)\n",
        "                self.add_inferred_relationships_to_graph_step_0(inferred_property_relationships, NodeType.PROPERTY, sent)\n",
        "            else:\n",
        "                added_edges = []\n",
        "                current_sentence = sent\n",
        "                prev_sentences.append(sent)\n",
        "                if len(prev_sentences) > self.context_length:\n",
        "                    prev_sentences.pop(0)\n",
        "                # from current sentence get all the text based nodes\n",
        "                current_sentence_text_based_nodes, current_sentence_text_based_words = \\\n",
        "                                            self.get_senteces_text_based_nodes([current_sentence], create_unexistent_nodes=True)\n",
        "\n",
        "                # get new relationships with chatgpt\n",
        "                current_all_text = sent.text\n",
        "                graph_active_nodes = self.graph.get_active_nodes(self.max_distance_from_active_nodes)\n",
        "                active_nodes_text = self.graph.get_nodes_str(graph_active_nodes)\n",
        "                active_nodes_edges_text, _ = self.graph.get_edges_str(graph_active_nodes)\n",
        "\n",
        "                only_text_based_graph_active_nodes = self.graph.get_active_nodes(self.max_distance_from_active_nodes, only_text_based=True)\n",
        "                only_text_based_active_nodes_text = self.graph.get_nodes_str(only_text_based_graph_active_nodes)\n",
        "                only_text_based_active_nodes_edges_text, _ = self.graph.get_edges_str(only_text_based_graph_active_nodes, only_text_based=True)\n",
        "\n",
        "                new_relationships = self.get_new_relationships(current_all_text,\n",
        "                                                       current_sentence_text_based_nodes,\n",
        "                                                       current_sentence_text_based_words,\n",
        "                                                       active_nodes_text,\n",
        "                                                       active_nodes_edges_text)\n",
        "                text_based_activated_nodes = current_sentence_text_based_nodes\n",
        "                for relationship in new_relationships:\n",
        "                    if len(relationship) != 3:\n",
        "                        continue\n",
        "                    if not relationship[0] or not relationship[2]:\n",
        "                        continue\n",
        "                    if relationship[0] == relationship[2]:\n",
        "                        continue\n",
        "                    if not isinstance(relationship[0], str) or not isinstance(relationship[2], str):\n",
        "                        continue\n",
        "                    source_node = self.get_node_from_new_relationship(relationship[0], graph_active_nodes,\n",
        "                                                            current_sentence_text_based_nodes,\n",
        "                                                            current_sentence_text_based_words,\n",
        "                                                            node_source=NodeSource.TEXT_BASED,\n",
        "                                                            create_node=True)\n",
        "                    dest_node = self.get_node_from_new_relationship(relationship[2], graph_active_nodes,\n",
        "                                                            current_sentence_text_based_nodes,\n",
        "                                                            current_sentence_text_based_words,\n",
        "                                                            node_source=NodeSource.TEXT_BASED,\n",
        "                                                            create_node=True)\n",
        "                    edge_label = relationship[1].replace(\"(edge)\", \"\").strip()\n",
        "                    if source_node is None or dest_node is None:\n",
        "                        continue\n",
        "\n",
        "                    print(\"New text relationship: \", relationship)\n",
        "                    # update to text based if needed\n",
        "                    if relationship[0] in current_sentence_text_based_words:\n",
        "                        source_node.node_source = NodeSource.TEXT_BASED\n",
        "                    if relationship[2] in current_sentence_text_based_words:\n",
        "                        dest_node.node_source = NodeSource.TEXT_BASED\n",
        "\n",
        "                    # create edge\n",
        "                    potential_new_edge = self.graph.add_edge(source_node, dest_node, edge_label, self.edge_forget)\n",
        "                    if potential_new_edge:\n",
        "                        added_edges.append(potential_new_edge)\n",
        "\n",
        "\n",
        "                # infer new relationships\n",
        "\n",
        "                # and then infer\n",
        "                current_all_text = sent.text\n",
        "                inferred_concept_relationships, inferred_property_relationships = \\\n",
        "                    self.infer_new_relationships(current_all_text,\n",
        "                                                        current_sentence_text_based_nodes,\n",
        "                                                        current_sentence_text_based_words,\n",
        "                                                        only_text_based_active_nodes_text,\n",
        "                                                        only_text_based_active_nodes_edges_text\n",
        "                                                        )\n",
        "\n",
        "                print(\"Inferred concept relationships: \", inferred_concept_relationships)\n",
        "                print(\"Inferred property relationships: \", inferred_property_relationships)\n",
        "                # add inferred relationships to graph\n",
        "                self.add_inferred_relationships_to_graph(inferred_concept_relationships, NodeType.CONCEPT,\n",
        "                                                            current_sentence_text_based_nodes,\n",
        "                                                            current_sentence_text_based_words,\n",
        "                                                            graph_active_nodes,\n",
        "                                                            added_edges)\n",
        "                self.add_inferred_relationships_to_graph(inferred_property_relationships, NodeType.PROPERTY,\n",
        "                                                            current_sentence_text_based_nodes,\n",
        "                                                            current_sentence_text_based_words,\n",
        "                                                            graph_active_nodes,\n",
        "                                                            added_edges)\n",
        "\n",
        "                # update graph through active nodes\n",
        "                self.graph.set_nodes_score_based_on_distance_from_active_nodes(text_based_activated_nodes)\n",
        "\n",
        "                self.reactivate_relevant_edges(self.graph.get_active_nodes(self.max_distance_from_active_nodes), \" \".join([s.text for s in prev_sentences]), added_edges)\n",
        "\n",
        "                self.graph.set_nodes_score_based_on_distance_from_active_nodes(text_based_activated_nodes)\n",
        "\n",
        "\n",
        "            print(\"All graph:\\n\\n\")\n",
        "            print(self.graph)\n",
        "            print(\"\\n\\n\")\n",
        "            print(\"=====================================================================================================\")\n",
        "            print(\"\\n\\n\")\n",
        "            print(\"Active graph:\\n\\n\")\n",
        "            print(self.graph.get_active_graph_repr())\n",
        "            print(\"\\n\\n\")\n",
        "            print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "            print(\"\\n\\n\\n\\n\")\n",
        "\n",
        "\n",
        "    def infer_new_relationships_step_0(self, sent: Span) -> Tuple[List[Tuple[str, str, str]], List[Tuple[str, str, str]]]:\n",
        "        # get all the text based nodes\n",
        "        current_sentence_text_based_nodes, current_sentence_text_based_words = \\\n",
        "                                    self.get_senteces_text_based_nodes([sent], create_unexistent_nodes=False)\n",
        "\n",
        "        nodes_from_text = \"\"\n",
        "        for i, node in enumerate(current_sentence_text_based_nodes):\n",
        "            nodes_from_text += f\" - ({current_sentence_text_based_words[i]}, {node.node_type})\\n\"\n",
        "\n",
        "        for _ in range(3):\n",
        "            try:\n",
        "                object_properties_dict = self.chatgpt.infer_objects_and_properties_first_sentence(nodes_from_text, sent.text)\n",
        "                break\n",
        "            except:\n",
        "                continue\n",
        "        else:\n",
        "            return [], []\n",
        "\n",
        "        for _ in range(3):\n",
        "            try:\n",
        "                new_relationships = self.chatgpt.generate_new_inferred_relationships_first_sentence(nodes_from_text,\n",
        "                                                            object_properties_dict[\"concepts\"][:self.max_new_concepts],\n",
        "                                                            object_properties_dict[\"properties\"][:self.max_new_properties],\n",
        "                                                            sent.text)\n",
        "                return new_relationships[\"concept_relationships\"], new_relationships[\"property_relationships\"]\n",
        "            except:\n",
        "                continue\n",
        "        return [], []\n",
        "\n",
        "    def infer_new_relationships(self, text: str,\n",
        "                                current_sentence_text_based_nodes: List[Node],\n",
        "                                current_sentence_text_based_words: List[str],\n",
        "                                graph_nodes_representation: str,\n",
        "                                graph_edges_representation: str) -> Tuple[List[Tuple[str, str, str]], List[Tuple[str, str, str]]]:\n",
        "        nodes_from_text = \"\"\n",
        "        for i, node in enumerate(current_sentence_text_based_nodes):\n",
        "            nodes_from_text += f\" - ({current_sentence_text_based_words[i]}, {node.node_type})\\n\"\n",
        "\n",
        "        for _ in range(3):\n",
        "            try:\n",
        "                object_properties_dict = self.chatgpt.infer_objects_and_properties(nodes_from_text, graph_nodes_representation,\n",
        "                                                                                   graph_edges_representation, text)\n",
        "                break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        for _ in range(3):\n",
        "            try:\n",
        "                new_relationships = self.chatgpt.generate_new_inferred_relationships(nodes_from_text, graph_nodes_representation,\n",
        "                                                                                     graph_edges_representation,\n",
        "                                                        object_properties_dict[\"concepts\"][:self.max_new_concepts],\n",
        "                                                        object_properties_dict[\"properties\"][:self.max_new_properties],\n",
        "                                                        text)\n",
        "                return new_relationships[\"concept_relationships\"], new_relationships[\"property_relationships\"]\n",
        "            except:\n",
        "                continue\n",
        "        return [], []\n",
        "\n",
        "    def reactivate_relevant_edges(self, active_nodes: List[Node], prev_sentences_text: str, newly_added_edges: List[Edge]) -> None:\n",
        "        edges_text, edges = self.graph.get_edges_str(self.graph.nodes, only_active=False)\n",
        "        relevant_edges_index = self.chatgpt.get_relevant_edges(edges_text, prev_sentences_text)[:self.nr_relevant_edges]\n",
        "        for i in relevant_edges_index:\n",
        "            print(\"Reactivating edge: \", edges[i-1])\n",
        "            edges[i-1].forget_score = self.edge_forget\n",
        "            edges[i-1].active = True\n",
        "        for j in range(1, len(edges)+1):\n",
        "            if j not in relevant_edges_index and edges[j-1] not in newly_added_edges:\n",
        "                print(\"Fading away: \", edges[j-1])\n",
        "                edges[j-1].fade_away()\n",
        "\n",
        "    def init_graph(self, sent: Span) -> None:\n",
        "        # get all the text based nodes\n",
        "        current_sentence_text_based_nodes, current_sentence_text_based_words = \\\n",
        "                                    self.get_senteces_text_based_nodes([sent], create_unexistent_nodes=True)\n",
        "\n",
        "        nodes_from_text = \"\"\n",
        "        for i, node in enumerate(current_sentence_text_based_nodes):\n",
        "            nodes_from_text += f\" - ({current_sentence_text_based_words[i]}, {node.node_type})\\n\"\n",
        "\n",
        "        relationships = self.chatgpt.get_new_relationships_first_sentence(nodes_from_text, sent.text)\n",
        "        print(f\"First sentence edges:\\n{relationships}\")\n",
        "\n",
        "        for relationship in relationships:\n",
        "            if len(relationship) != 3:\n",
        "                continue\n",
        "            if not relationship[0] or not relationship[2]:\n",
        "                continue\n",
        "            if relationship[0] == relationship[2]:\n",
        "                continue\n",
        "            if not isinstance(relationship[0], str) or not isinstance(relationship[2], str):\n",
        "                continue\n",
        "            source_node = self.get_node_from_text(relationship[0],\n",
        "                                                    current_sentence_text_based_nodes,\n",
        "                                                    current_sentence_text_based_words,\n",
        "                                                    node_source=NodeSource.TEXT_BASED,\n",
        "                                                    create_node=True)\n",
        "            dest_node = self.get_node_from_text(relationship[2],\n",
        "                                                    current_sentence_text_based_nodes,\n",
        "                                                    current_sentence_text_based_words,\n",
        "                                                    node_source=NodeSource.TEXT_BASED,\n",
        "                                                    create_node=True)\n",
        "            edge_label = relationship[1].replace(\"(edge)\", \"\").strip()\n",
        "            if source_node is None or dest_node is None:\n",
        "                continue\n",
        "\n",
        "            # create edge\n",
        "            self.graph.add_edge(source_node, dest_node, edge_label, self.edge_forget)\n",
        "\n",
        "    def get_new_relationships(self, text,\n",
        "                                    current_sentence_text_based_nodes: List[Node],\n",
        "                                    current_sentence_text_based_words: List[str],\n",
        "                                    graph_nodes_representation: str,\n",
        "                                    graph_edges_representation: str) -> List[Tuple[str, str, str]]:\n",
        "        nodes_from_text = \"\"\n",
        "        for i, node in enumerate(current_sentence_text_based_nodes):\n",
        "            nodes_from_text += f\" - ({current_sentence_text_based_words[i]}, {node.node_type})\\n\"\n",
        "\n",
        "        relationships = self.chatgpt.get_new_relationships(nodes_from_text, graph_nodes_representation, graph_edges_representation, text)\n",
        "        return relationships\n",
        "\n",
        "    def add_inferred_relationships_to_graph_step_0(self, inferred_relationships: List[Tuple[str, str, str]], node_type: NodeType,\n",
        "                                                   sent: Span) -> None:\n",
        "        current_sentence_text_based_nodes, current_sentence_text_based_words = \\\n",
        "                                    self.get_senteces_text_based_nodes([sent], create_unexistent_nodes=False)\n",
        "        for relationship in inferred_relationships:\n",
        "            print(relationship)\n",
        "            if len(relationship) != 3:\n",
        "                continue\n",
        "            if not relationship[0] or not relationship[2]:\n",
        "                continue\n",
        "            if relationship[0] == relationship[2]:\n",
        "                continue\n",
        "            if not isinstance(relationship[0], str) or not isinstance(relationship[2], str):\n",
        "                continue\n",
        "            source_node = self.get_node_from_text(relationship[0],\n",
        "                                                    current_sentence_text_based_nodes,\n",
        "                                                    current_sentence_text_based_words,\n",
        "                                                    node_source=NodeSource.INFERENCE_BASED,\n",
        "                                                    create_node=False)\n",
        "            dest_node = self.get_node_from_text(relationship[2],\n",
        "                                                    current_sentence_text_based_nodes,\n",
        "                                                    current_sentence_text_based_words,\n",
        "                                                    node_source=NodeSource.INFERENCE_BASED,\n",
        "                                                    create_node=False)\n",
        "            edge_label = relationship[1].replace(\"(edge)\", \"\").strip()\n",
        "            if source_node is None:\n",
        "                source_node = self.graph.add_or_get_node(self.get_concept_lemmas(relationship[0]), relationship[0], node_type, NodeSource.INFERENCE_BASED)\n",
        "\n",
        "            if dest_node is None:\n",
        "                dest_node = self.graph.add_or_get_node(self.get_concept_lemmas(relationship[2]), relationship[2], node_type, NodeSource.INFERENCE_BASED)\n",
        "\n",
        "            self.graph.add_edge(source_node, dest_node, edge_label, self.edge_forget)\n",
        "\n",
        "    def add_inferred_relationships_to_graph(self, inferred_relationships: List[Tuple[str, str, str]], node_type: NodeType,\n",
        "                                                curr_sentences_nodes: List[Node],\n",
        "                                                curr_sentences_words: List[str],\n",
        "                                                active_graph_nodes: List[Node],\n",
        "                                                added_edges: List[Edge]) -> None:\n",
        "        for relationship in inferred_relationships:\n",
        "            print(relationship)\n",
        "            if len(relationship) != 3:\n",
        "                continue\n",
        "            if not relationship[0] or not relationship[2]:\n",
        "                continue\n",
        "            if relationship[0] == relationship[2]:\n",
        "                continue\n",
        "            if not isinstance(relationship[0], str) or not isinstance(relationship[2], str):\n",
        "                continue\n",
        "            source_node = self.get_node_from_new_relationship(relationship[0], active_graph_nodes,\n",
        "                                                    curr_sentences_nodes,\n",
        "                                                    curr_sentences_words,\n",
        "                                                    node_source=NodeSource.INFERENCE_BASED,\n",
        "                                                    create_node=False)\n",
        "            dest_node = self.get_node_from_new_relationship(relationship[2], active_graph_nodes,\n",
        "                                                    curr_sentences_nodes,\n",
        "                                                    curr_sentences_words,\n",
        "                                                    node_source=NodeSource.INFERENCE_BASED,\n",
        "                                                    create_node=False)\n",
        "            edge_label = relationship[1].replace(\"(edge)\", \"\").strip()\n",
        "            if source_node is None:\n",
        "                source_node = self.graph.add_or_get_node(self.get_concept_lemmas(relationship[0]), relationship[0], node_type, NodeSource.INFERENCE_BASED)\n",
        "\n",
        "            if dest_node is None:\n",
        "                dest_node = self.graph.add_or_get_node(self.get_concept_lemmas(relationship[2]), relationship[2], node_type, NodeSource.INFERENCE_BASED)\n",
        "\n",
        "            # create edge\n",
        "            potential_edge = self.graph.add_edge(source_node, dest_node, edge_label, self.edge_forget)\n",
        "            if potential_edge:\n",
        "                added_edges.append(potential_edge)\n",
        "\n",
        "    def get_node_from_text(self, text: str,\n",
        "                                curr_sentences_nodes: List[Node],\n",
        "                                curr_sentences_words: List[str],\n",
        "                                node_source: NodeSource,\n",
        "                                create_node: bool) -> Optional[Node]:\n",
        "        if text in curr_sentences_words:\n",
        "            return curr_sentences_nodes[curr_sentences_words.index(text)]\n",
        "        if create_node:\n",
        "            lemmas = self.get_concept_lemmas(text)\n",
        "            if self.has_noun(text):\n",
        "                new_node = self.graph.add_or_get_node(lemmas, text, NodeType.CONCEPT, node_source)\n",
        "            else:\n",
        "                new_node = self.graph.add_or_get_node(lemmas, text, NodeType.PROPERTY, node_source)\n",
        "            return new_node\n",
        "        return None\n",
        "\n",
        "    def get_node_from_new_relationship(self, text: str, graph_active_nodes: List[Node],\n",
        "                                curr_sentences_nodes: List[Node],\n",
        "                                curr_sentences_words: List[str],\n",
        "                                node_source: NodeSource,\n",
        "                                create_node: bool) -> Optional[Node]:\n",
        "        if text in curr_sentences_words:\n",
        "            return curr_sentences_nodes[curr_sentences_words.index(text)]\n",
        "        else:\n",
        "            lemmas = self.get_concept_lemmas(text)\n",
        "            for node in graph_active_nodes:\n",
        "                if lemmas == node.lemmas:\n",
        "                    return node\n",
        "        if create_node:\n",
        "            lemmas = self.get_concept_lemmas(text)\n",
        "            if self.has_noun(text):\n",
        "                new_node = self.graph.add_or_get_node(lemmas, text, NodeType.CONCEPT, node_source)\n",
        "            else:\n",
        "                new_node = self.graph.add_or_get_node(lemmas, text, NodeType.PROPERTY, node_source)\n",
        "            return new_node\n",
        "        return None\n",
        "\n",
        "    def is_content_word_and_non_stopword(self, token: Token, pos_list: List[str] = [\"NOUN\", \"PROPN\", \"ADJ\",]) -> bool:\n",
        "        #  \"VERB\", \"ADV\" not included by default\n",
        "        return (token.pos_ in pos_list) and (token.lemma_ not in self.spacy_nlp.Defaults.stop_words)\n",
        "\n",
        "    def get_content_words_from_sent(self, sent: Span) -> List[Token]:\n",
        "        return [token for token in sent if self.is_content_word_and_non_stopword(token)]\n",
        "\n",
        "    def get_concept_lemmas(self, concept: str):\n",
        "        doc = self.spacy_nlp(concept)\n",
        "        return [token.lemma_ for token in doc]\n",
        "\n",
        "    def has_noun(self, text: str) -> bool:\n",
        "        span = self.spacy_nlp(text)\n",
        "        for token in span:\n",
        "            if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\":\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def get_sentences_concept_nodes(self, previous_sentences: List[Span]) -> List[Node]:\n",
        "        concept_nodes = []\n",
        "        for sent in previous_sentences:\n",
        "            content_words = self.get_content_words_from_sent(sent)\n",
        "            for word in content_words:\n",
        "                node = self.graph.get_node(word.lemma_)\n",
        "                if node is not None and node.node_type == NodeType.CONCEPT:\n",
        "                    concept_nodes.append(node)\n",
        "        return concept_nodes\n",
        "\n",
        "    def get_senteces_text_based_nodes(self, previous_sentences: List[Span],\n",
        "                                      create_unexistent_nodes: bool = True) -> Tuple[List[Token], List[str]]:\n",
        "        text_based_nodes = []\n",
        "        text_based_words = []\n",
        "        for sent in previous_sentences:\n",
        "            content_words = self.get_content_words_from_sent(sent)\n",
        "            for word in content_words:\n",
        "                node = self.graph.get_node([word.lemma_])\n",
        "                if node is not None: # node exists in the graph, don't care about the node type\n",
        "                    node.add_actual_text(word.text)\n",
        "                    text_based_nodes.append(node)\n",
        "                    text_based_words.append(word.text)\n",
        "                else: # node doesn't exist in the graph\n",
        "                    if create_unexistent_nodes:\n",
        "                        if word.pos_ == \"ADJ\":\n",
        "                            new_node = self.graph.add_or_get_node([word.lemma_], word.text, NodeType.PROPERTY, NodeSource.TEXT_BASED)\n",
        "                        else:\n",
        "                            new_node = self.graph.add_or_get_node([word.lemma_], word.text, NodeType.CONCEPT, NodeSource.TEXT_BASED)\n",
        "                        text_based_nodes.append(new_node)\n",
        "                        text_based_words.append(word.text)\n",
        "        return text_based_nodes, text_based_words"
      ],
      "metadata": {
        "id": "_xHkwDAHCbWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amoc = AMoCv4(max_distance_from_active_nodes=MAX_DISTANCE_FROM_ACTIVE_NODES,\n",
        "              max_new_concepts=MAX_NEW_CONCEPTS,\n",
        "              max_new_properties=MAX_NEW_PROPERTIES,\n",
        "              context_length=CONTEXT_LENGTH,\n",
        "              edge_forget=EDGE_FORGET,\n",
        "              nr_relevant_edges=NR_RELEVANT_EDGES,\n",
        "              debug=DEBUG)\n",
        "text = \"A young knight rode through the forest. The knight was unfamiliar with the country. Suddenly, a dragon appeared. The dragon was kidnapping a beautiful princess. The knight wanted to free the princess. The knight wanted to marry the princess. The knight hurried after the dragon. The knight and the dragon fought for life and death. Soon, the knight's armor was completely scorched. At last, the knight killed the dragon. The knight freed the princess. The princess was very thankful to the knight. The princess married the knight.\"\n",
        "amoc.analyze(text, replace_prononuns=False)"
      ],
      "metadata": {
        "id": "EjET6QMWC3Wt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}